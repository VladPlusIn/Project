{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "                                 0                  1   2   \\\n",
      "0  b006d2236cd8786f8269e3bd60dd795f  20130318000100765   1   \n",
      "1  72f80b647a1ee74dd131c00f5dbb0174  20130318000100802   1   \n",
      "2  6f8cee7aecd741b28ad303e9bb9cf1eb  20130318000100827   1   \n",
      "3  58fcbfa5f1c6381a207456157301d9d3  20130318000100837   1   \n",
      "4  f6c97f428a534bc515a52e1eab9b53cf  20130318000100840   1   \n",
      "\n",
      "                                 3   \\\n",
      "0  c43a65560b3c8adc7cfe24ef38e82398   \n",
      "1  d09e956039c402a4c36513920c06bc84   \n",
      "2  519a2259e67cc42c5d422a16a28b5b0a   \n",
      "3  46f2497b959b6e5f331032c5a8985281   \n",
      "4  6fa09a1916b9eb75010f756e4fb276fb   \n",
      "\n",
      "                                                  4              5   6    7   \\\n",
      "0  Mozilla/4.0 (compatible; MSIE 6.0; Windows NT ...   60.190.192.*  94  100   \n",
      "1  Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.1...    175.170.0.*  40   42   \n",
      "2  Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.1...  123.186.178.*  40   45   \n",
      "3  Mozilla/4.0 (compatible; MSIE 6.0; Windows NT ...  180.125.218.*  80   85   \n",
      "4  Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.7...  117.148.123.*   0    0   \n",
      "\n",
      "   8                        9   ...   14  15 16  17  \\\n",
      "0   2       eF1gtp57dNFrw9Kbu-  ...   60   0  0  13   \n",
      "1   2     3F9-GK9SGqs8jdpz5SqW  ...   90   2  0   5   \n",
      "2   1  5F97t5E0BTK7XhNrUMpENpn  ...  600   2  1   0   \n",
      "3   2          trqRTvprB9b7gsz  ...  250   2  0   5   \n",
      "4   2     trqRTuNygI5ogg5A5SqW  ...  250   2  0   5   \n",
      "\n",
      "                                 18   19  20  \\\n",
      "0  28425676c2469651ba969a88529eeec8  300  13   \n",
      "1  5aca4c5f29e59e425c7ea657fdaac91e  300  25   \n",
      "2  36391fa23e0928a93cd51ea8af344b82  300  13   \n",
      "3  f206493d1a82b7d977075b20b7afd5f4  300  24   \n",
      "4  f206493d1a82b7d977075b20b7afd5f4  300  57   \n",
      "\n",
      "                                 21 22  23  \n",
      "0  9f4e2f16b6873a7eb504df6f61b24044  0   0  \n",
      "1  df6f61b2409f4e2f16b6873a7eb50444  0   0  \n",
      "2  df6f61b2409f4e2f16b6873a7eb50444  0   0  \n",
      "3  df6f61b2409f4e2f16b6873a7eb50444  0   0  \n",
      "4  df6f61b2409f4e2f16b6873a7eb50444  0   0  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2594386 entries, 0 to 2594385\n",
      "Data columns (total 24 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   0       object \n",
      " 1   1       int64  \n",
      " 2   2       int64  \n",
      " 3   3       object \n",
      " 4   4       object \n",
      " 5   5       object \n",
      " 6   6       int64  \n",
      " 7   7       int64  \n",
      " 8   8       int64  \n",
      " 9   9       object \n",
      " 10  10      object \n",
      " 11  11      float64\n",
      " 12  12      object \n",
      " 13  13      int64  \n",
      " 14  14      int64  \n",
      " 15  15      int64  \n",
      " 16  16      int64  \n",
      " 17  17      int64  \n",
      " 18  18      object \n",
      " 19  19      int64  \n",
      " 20  20      int64  \n",
      " 21  21      object \n",
      " 22  22      int64  \n",
      " 23  23      int64  \n",
      "dtypes: float64(1), int64(14), object(9)\n",
      "memory usage: 475.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the extracted file\n",
    "file_path = '/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/testing1st/leaderboard.test.data.20130318_20.txt'  # Replace with actual path\n",
    "\n",
    "# Load the dataset (assuming tab-separated values)\n",
    "data = pd.read_csv(file_path, sep='\\t', header=None)  # Adjust 'header' if there are headers in the file\n",
    "\n",
    "# Explore the first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Get summary information of the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "data.info()\n",
    "\n",
    "# If there are categorical columns, you can preprocess them like so:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example preprocessing (adjust column indices based on data)\n",
    "categorical_columns = [1, 2, 3]  # Replace with actual indices of categorical columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col].astype(str))  # Convert categorical to numerical\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# The data is now ready for model training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def process_bid_files(datapath):\n",
    "    # List all decompressed bid files (assumes the files have been decompressed)\n",
    "    bid_files = [f for f in os.listdir(datapath) if f.startswith('bid') and f.endswith('.txt')]\n",
    "\n",
    "    for bid_file in bid_files:\n",
    "        # Convert each bid file to CSV\n",
    "        bid_file_path = os.path.join(datapath, bid_file)\n",
    "        csv_file_path = bid_file_path.replace('.txt', '.csv')\n",
    "        \n",
    "        print(f\"Processing {bid_file_path} -> {csv_file_path}\")\n",
    "        \n",
    "        with open(csv_file_path, 'w', newline='') as csv_out:\n",
    "            spam_writer = csv.writer(csv_out, dialect='excel')\n",
    "            \n",
    "            with open(bid_file_path, 'r') as log_in:\n",
    "                for line in log_in:\n",
    "                    line_list = line.strip('\\n').split('\\t')\n",
    "                    spam_writer.writerow(line_list)\n",
    "        \n",
    "        print(f\"Completed processing {bid_file_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Data path setup (adjust as necessary)\n",
    "    data_path = '/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st'\n",
    "    \n",
    "    # Process the bid files after decompression\n",
    "    process_bid_files(data_path)\n",
    "    \n",
    "    # Now you can proceed with further data preparation using the CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130313.txt -> /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130313.csv\n",
      "Completed processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130313.txt\n",
      "Processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130311.txt -> /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130311.csv\n",
      "Completed processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130311.txt\n",
      "Processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130316.txt -> /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130316.csv\n",
      "Completed processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130316.txt\n",
      "Processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130314.txt -> /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130314.csv\n",
      "Completed processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130314.txt\n",
      "Processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130315.txt -> /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130315.csv\n",
      "Completed processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130315.txt\n",
      "Processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130317.txt -> /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130317.csv\n",
      "Completed processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130317.txt\n",
      "Processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130312.txt -> /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130312.csv\n",
      "Completed processing /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130312.txt\n",
      "Converting to LIBSVM encoding...\n",
      "Feature size: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import operator\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Function to set a random seed for reproducibility\n",
    "def setup_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "# Function to convert the time into fractional intervals\n",
    "def to_time_frac(hour, minute, time_frac_dict):\n",
    "    for key in time_frac_dict[hour].keys():\n",
    "        if key[0] <= minute <= key[1]:\n",
    "            return str(time_frac_dict[hour][key])\n",
    "\n",
    "# Function to transform and encode features based on specific rules\n",
    "def feat_trans(name, content, oses, browsers):\n",
    "    content = content.lower()\n",
    "    if name == \"useragent\":\n",
    "        # Handle OS and browser detection\n",
    "        operation = next((o for o in oses if o in content), \"other\")\n",
    "        browser = next((b for b in browsers if b in content), \"other\")\n",
    "        return operation + \"_\" + browser\n",
    "    if name == \"slotprice\":\n",
    "        price = int(content)\n",
    "        if price > 100:\n",
    "            return \"101+\"\n",
    "        elif price > 50:\n",
    "            return \"51-100\"\n",
    "        elif price > 10:\n",
    "            return \"11-50\"\n",
    "        elif price > 0:\n",
    "            return \"1-10\"\n",
    "        else:\n",
    "            return \"0\"\n",
    "\n",
    "# Main function to prepare data (can be extended for different formats)\n",
    "def to_libsvm_encode(datapath, time_frac_dict):\n",
    "    print('Converting to LIBSVM encoding...')\n",
    "    \n",
    "    # Known OSes and Browsers\n",
    "    oses = [\"windows\", \"ios\", \"mac\", \"android\", \"linux\"]\n",
    "    browsers = [\"chrome\", \"sogou\", \"maxthon\", \"safari\", \"firefox\", \"theworld\", \"opera\", \"ie\"]\n",
    "\n",
    "    # Feature columns that require encoding\n",
    "    f1s = [\"weekday\", \"hour\", \"IP\", \"region\", \"city\", \"adexchange\", \"domain\", \"slotid\", \"slotwidth\", \"slotheight\",\n",
    "           \"slotvisibility\", \"slotformat\", \"creative\", \"advertiser\"]\n",
    "    f1sp = [\"useragent\", \"slotprice\"]\n",
    "\n",
    "    # Load the CSV (converted from the log file earlier)\n",
    "    fi = open(os.path.join(datapath, 'train.bid.csv'), 'r')\n",
    "\n",
    "    # Initialize feature indices\n",
    "    featindex = {}\n",
    "    maxindex = 0  # Keep track of the max index\n",
    "\n",
    "    first = True\n",
    "    namecol = {}  # Column name index mapping\n",
    "\n",
    "    # Processing training data and generating feature indices\n",
    "    for line in fi:\n",
    "        s = line.split(',')\n",
    "        if first:\n",
    "            first = False\n",
    "            for i in range(len(s)):\n",
    "                namecol[s[i].strip()] = i\n",
    "                if i > 0:\n",
    "                    featindex[str(i) + ':other'] = maxindex\n",
    "                    maxindex += 1\n",
    "            continue\n",
    "\n",
    "        # Process each feature in `f1s`\n",
    "        for f in f1s:\n",
    "            col = namecol[f]\n",
    "            content = s[col]\n",
    "            feat = str(col) + ':' + content\n",
    "            if feat not in featindex:\n",
    "                featindex[feat] = maxindex\n",
    "                maxindex += 1\n",
    "\n",
    "        # Process transformed features in `f1sp`\n",
    "        for f in f1sp:\n",
    "            col = namecol[f]\n",
    "            content = feat_trans(f, s[col], oses, browsers)\n",
    "            feat = str(col) + ':' + content\n",
    "            if feat not in featindex:\n",
    "                featindex[feat] = maxindex\n",
    "                maxindex += 1\n",
    "\n",
    "    print('Feature size:', maxindex)\n",
    "    return featindex  # Return the feature index dictionary for further processing\n",
    "\n",
    "# Time Fraction Dictionary (24 hours, each hour split into 15-minute intervals)\n",
    "def create_time_frac_dict():\n",
    "    time_frac_dict = {}\n",
    "    count = 0\n",
    "    for i in range(24):\n",
    "        hour_frac_dict = {}\n",
    "        for item in [(0, 15), (15, 30), (30, 45), (45, 60)]:\n",
    "            hour_frac_dict[item] = count\n",
    "            count += 1\n",
    "        time_frac_dict[i] = hour_frac_dict\n",
    "    return time_frac_dict\n",
    "\n",
    "# Function to convert bid log files into CSV format\n",
    "def process_bid_files(datapath):\n",
    "    # List all decompressed bid files\n",
    "    bid_files = [f for f in os.listdir(datapath) if f.startswith('bid') and f.endswith('.txt')]\n",
    "\n",
    "    for bid_file in bid_files:\n",
    "        # Convert each bid file to CSV\n",
    "        bid_file_path = os.path.join(datapath, bid_file)\n",
    "        csv_file_path = bid_file_path.replace('.txt', '.csv')\n",
    "        \n",
    "        print(f\"Processing {bid_file_path} -> {csv_file_path}\")\n",
    "        \n",
    "        with open(csv_file_path, 'w', newline='') as csv_out:\n",
    "            spam_writer = csv.writer(csv_out, dialect='excel')\n",
    "            \n",
    "            with open(bid_file_path, 'r') as log_in:\n",
    "                for line in log_in:\n",
    "                    line_list = line.strip('\\n').split('\\t')\n",
    "                    spam_writer.writerow(line_list)\n",
    "        \n",
    "        print(f\"Completed processing {bid_file_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Data path setup (example path, adjust as necessary)\n",
    "    data_path = '/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st'\n",
    "    \n",
    "    # Process the bid files after decompression\n",
    "    process_bid_files(data_path)\n",
    "    \n",
    "    # Time Frac Dictionary for 15-minute intervals\n",
    "    time_frac_dict = create_time_frac_dict()\n",
    "\n",
    "    # Convert the data to LIBSVM format and extract feature indices\n",
    "    featindex = to_libsvm_encode(data_path, time_frac_dict)\n",
    "    \n",
    "    # Further processing can happen after this to prepare the data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130316.csv into /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv\n",
      "Combined /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130317.csv into /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv\n",
      "Combined /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130312.csv into /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv\n",
      "Combined /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130314.csv into /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv\n",
      "Combined /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130315.csv into /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv\n",
      "Combined /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130311.csv into /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv\n",
      "Combined /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/bid.20130313.csv into /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv\n",
      "All CSV files combined into /home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv\n",
      "Converting to LIBSVM encoding...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'weekday'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m time_frac_dict \u001b[38;5;241m=\u001b[39m create_time_frac_dict()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Step 3: Convert the data to LIBSVM format and extract feature indices\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m featindex \u001b[38;5;241m=\u001b[39m \u001b[43mto_libsvm_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_frac_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Further processing can happen after this to prepare the data for model training\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 77\u001b[0m, in \u001b[0;36mto_libsvm_encode\u001b[0;34m(datapath, time_frac_dict)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Process each feature in `f1s`\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m f1s:\n\u001b[0;32m---> 77\u001b[0m     col \u001b[38;5;241m=\u001b[39m \u001b[43mnamecol\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     78\u001b[0m     content \u001b[38;5;241m=\u001b[39m s[col]\n\u001b[1;32m     79\u001b[0m     feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(col) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m content\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weekday'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to combine all CSV files into one\n",
    "def combine_csv_files(datapath, output_file='train.bid.csv'):\n",
    "    # List all CSV files generated from bid logs\n",
    "    csv_files = [f for f in os.listdir(datapath) if f.startswith('bid') and f.endswith('.csv')]\n",
    "    \n",
    "    combined_csv_path = os.path.join(datapath, output_file)\n",
    "    \n",
    "    with open(combined_csv_path, 'w', newline='') as out_file:\n",
    "        csv_writer = csv.writer(out_file)\n",
    "        header_written = False\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            csv_file_path = os.path.join(datapath, csv_file)\n",
    "            \n",
    "            with open(csv_file_path, 'r') as in_file:\n",
    "                csv_reader = csv.reader(in_file)\n",
    "                \n",
    "                for i, row in enumerate(csv_reader):\n",
    "                    # Write header only once\n",
    "                    if i == 0 and header_written:\n",
    "                        continue\n",
    "                    if i == 0:\n",
    "                        header_written = True\n",
    "                    csv_writer.writerow(row)\n",
    "                    \n",
    "            print(f\"Combined {csv_file_path} into {combined_csv_path}\")\n",
    "    \n",
    "    print(f\"All CSV files combined into {combined_csv_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Data path setup\n",
    "    data_path = '/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st'\n",
    "    \n",
    "    # Step 1: Combine all the bid CSV files into a single train.bid.csv\n",
    "    combine_csv_files(data_path)\n",
    "\n",
    "    # Step 2: Time Frac Dictionary for 15-minute intervals\n",
    "    time_frac_dict = create_time_frac_dict()\n",
    "\n",
    "    # Step 3: Convert the data to LIBSVM format and extract feature indices\n",
    "    featindex = to_libsvm_encode(data_path, time_frac_dict)\n",
    "    \n",
    "    # Further processing can happen after this to prepare the data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the CSV file: Index(['7ccd6d80ef7b50127eaa453b8f06075a', '20130316003300692',\n",
      "       '37a6259cc0c1dae299a7866489dff0bd',\n",
      "       'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727),gzip(gfe),gzip(gfe)',\n",
      "       '124.193.57.*', '1', '1.1', '2', 'trqRTvdbjq17DqKbuKz',\n",
      "       '240898007d3953fbdcb5c8b934942b6f', 'Unnamed: 10', '1938265360', '336',\n",
      "       '280', '1.2', '0', '5', '02adb1d6bc7233c0735dbefe9bb85ecd', '300'],\n",
      "      dtype='object')\n",
      "   7ccd6d80ef7b50127eaa453b8f06075a  20130316003300692  \\\n",
      "0   4e44d8345b95902e92cdeefa40f5c81  20130316003300696   \n",
      "1  2ed51eeeef2d6fbdda9f856743a0d801  20130316003300701   \n",
      "2  def432610104f0492ce889114cb19761  20130316003300725   \n",
      "3  848d5122077d69ab89fe9c5cdd8687f3  20130316003300731   \n",
      "4  ddd326e4d0107aae9a5b0706e67f1116  20130316003300734   \n",
      "\n",
      "   37a6259cc0c1dae299a7866489dff0bd  \\\n",
      "0  611a964c794e51980cc1ea370f201e05   \n",
      "1  6462f28bf9ce7800d14a40815e446275   \n",
      "2  bc2b62a048c37437cb45db5b211f4daa   \n",
      "3  e7dfa349387d35e098a4f4c150fe87ef   \n",
      "4  1bd638ab431c9ec18925dd9458ea5a10   \n",
      "\n",
      "  Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727),gzip(gfe),gzip(gfe)  \\\n",
      "0  Mozilla/4.0 (compatible; MSIE 8.0; Windows NT ...                                                        \n",
      "1  Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKi...                                                        \n",
      "2  Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.1...                                                        \n",
      "3  Mozilla/5.0 (compatible; MSIE 9.0; Windows NT ...                                                        \n",
      "4  Mozilla/5.0 (Windows NT 6.0) AppleWebKit/537.1...                                                        \n",
      "\n",
      "   124.193.57.*    1  1.1  2       trqRTvdbjq17DqKbuKz  \\\n",
      "0    121.8.55.*  216  217  2        trqRTJkrjouf1mKYUV   \n",
      "1   112.95.83.*  216  219  2      trqRTvKaXTKfgg24JKTI   \n",
      "2   112.2.228.*   80   81  2  trqRTudvg9uYXhMouScWvpdh   \n",
      "3  218.88.123.*  276  277  2                       NaN   \n",
      "4   106.121.1.*  216  216  2        trqRTuN-XIuc1mKYUV   \n",
      "\n",
      "   240898007d3953fbdcb5c8b934942b6f                        Unnamed: 10  \\\n",
      "0  4c23442b828b551c34c0086ae4801479                                NaN   \n",
      "1  7ef8a78c400964b721905a89a143b094                                NaN   \n",
      "2  a17625973ec6637a34273291e8611079                                NaN   \n",
      "3   2a230d22d6725b124714a01f5ba6359  1b2c96de23f29998.anonymous.google   \n",
      "4  b9b27f86cd5409b505b66e27470765af                                NaN   \n",
      "\n",
      "   1938265360  336  280  1.2  0  5  02adb1d6bc7233c0735dbefe9bb85ecd  300  \n",
      "0   553007353  728   90    2  0  5  f7e7cdcd8b8ed4d6682d78c5b8c4446c  300  \n",
      "1  1030498436  250  250    1  0  5  d76818d93532855570f2af04f52b1ef1  300  \n",
      "2  4197382338  728   90    1  0  5  f7e7cdcd8b8ed4d6682d78c5b8c4446c  300  \n",
      "3   189624444  250  250    2  0  4  d76818d93532855570f2af04f52b1ef1  300  \n",
      "4  2578891183  468   60    2  0  5  4937b21d6f6c38560823917e19403fa7  300  \n"
     ]
    }
   ],
   "source": [
    "csv_file_path = '/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training1st/train.bid.csv'\n",
    "\n",
    "# Load and print the first few rows of the data along with column names\n",
    "data = pd.read_csv(csv_file_path, nrows=5)\n",
    "print(\"Column names in the CSV file:\", data.columns)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20566/1510467096.py:4: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  bidding_log = pd.read_csv('/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training2nd/bid.20130606.txt', sep='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   b382c1c156dcbbd5b9317cb50f6a747b  20130606000104008  Vh16OwT6OQNUXbj  \\\n",
      "0   7b6195de0d14203f92001da653bf1de  20130606000104009  Vhkr1vpROHuhQWB   \n",
      "1  2ea9fe21cf7350fcb5696d8cff0bbeaa  20130606000104012  VhKdLnuY3tlhXMa   \n",
      "2  8a15b98c8f9e60d4f92aaab01acf52a4  20130606000104014  VhTVORqG36N6qMj   \n",
      "3  faf17eac9cabf1be598f4e75f40d501d  20130606000104016  VhL01pk8OTkW3Mc   \n",
      "4  c60989edb8618fb1ab70ae56824af7ee  20130606000104017              NaN   \n",
      "\n",
      "  mozilla/4.0 (compatible; msie 6.0; windows nt 5.1; sv1; qqdownload 718)  \\\n",
      "0  Mozilla/4.0 (compatible; MSIE 8.0; Windows NT ...                        \n",
      "1  mozilla/4.0 (compatible; msie 8.0; windows nt ...                        \n",
      "2  mozilla/5.0 (windows nt 5.1) applewebkit/537.1...                        \n",
      "3  mozilla/5.0 (windows nt 5.1) applewebkit/537.1...                        \n",
      "4  mozilla/4.0 (compatible; msie 8.0; windows nt ...                        \n",
      "\n",
      "   180.127.189.*   80   87  1 tFKETuqyMo1mjMp45SqfNX  \\\n",
      "0  113.119.105.*  216  217  2   trqRTuToMTNUjM9r5rMi   \n",
      "1   42.184.148.*   65   69  1   trqRTvpogNlyDok4JKTI   \n",
      "2   114.100.37.*  106  117  1       lsxSl559Xql7FmMs   \n",
      "3   58.100.240.*   94   95  1        tK1NTu1YP5scFsf   \n",
      "4     112.0.91.*   80   91  1   eSKot19-gNb7gspy5SqW   \n",
      "\n",
      "   249b2c34247d400ef1cd3c6bfda4f12a  ...   mm_11402872_1272384_3182279  300  \\\n",
      "0  74419a072f8927222a1fd8aaa18cce56  ...                     433287550  468   \n",
      "1  134db65c2b66d8468d00bf42fd9f912f  ...   mm_10032051_2374052_9219530  950   \n",
      "2  8c9742e63497713b97ac7e780a8f9a12  ...  mm_30232185_2681382_11190685  950   \n",
      "3  e22930480589abcc1468854cb3403314  ...  mm_10075660_3500949_11453278  950   \n",
      "4  d11705fe1d57c663c8c7cba6f9c09fc9  ...  mm_33726324_3429225_11249067  300   \n",
      "\n",
      "   250  1.1  1.2  0  00fccc64a1ee2809348509b7ac2a97a5  227  3427  null  \n",
      "0   60    1    0  5  2f88fc9cf0141b5bbaf251cab07f4ce7  300  3386   NaN  \n",
      "1   90    1    1  0  23d6dade7ed21cea308205b37594003e  227  3427   NaN  \n",
      "2   90    0    1  0  23d6dade7ed21cea308205b37594003e  227  3427   NaN  \n",
      "3   90    0    1  0  d5cecca9a6cbd7a0a48110f1306b26d1  227  3358   NaN  \n",
      "4  250    2    1  0  00fccc64a1ee2809348509b7ac2a97a5  227  3427   NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "bidding_log = pd.read_csv('/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training2nd/bid.20130606.txt', sep='\\t')\n",
    "impression_log = pd.read_csv('/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training2nd/imp.20130606.txt', sep='\\t')\n",
    "click_log = pd.read_csv('/home/vladplyusnin/tftest/Deep-Learning-COPSCI764/Project/Data sets/ipinyou.contest.dataset/training2nd/clk.20130606.txt', sep='\\t')\n",
    "\n",
    "# Display the first few rows of bidding data\n",
    "print(bidding_log.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
